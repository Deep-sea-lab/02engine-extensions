<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>神经网络扩展 1.73 - 介绍文档</title>
    <style>
        :root {
            --primary-color: #4361ee;
            --secondary-color: #3f37c9;
            --accent-color: #4cc9f0;
            --success-color: #4cc9f0;
            --text-primary: #1d3557;
            --text-secondary: #457b9d;
            --bg-primary: #f8f9fa;
            --bg-secondary: #e9ecef;
            --card-bg: #ffffff;
            --border-color: #dee2e6;
            --shadow-color: rgba(0, 0, 0, 0.1);
            --highlight-gradient: linear-gradient(135deg, #4361ee, #4cc9f0);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--text-primary);
            background-color: var(--bg-primary);
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background: var(--highlight-gradient);
            color: white;
            padding: 60px 0 80px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: radial-gradient(circle at 20% 80%, rgba(76, 201, 240, 0.3) 0%, rgba(67, 97, 238, 0.1) 100%);
            animation: backgroundPulse 8s infinite alternate;
        }

        .header-content {
            position: relative;
            z-index: 2;
        }

        .header-content h1 {
            font-size: 3rem;
            margin-bottom: 20px;
            font-weight: 700;
            letter-spacing: -1px;
            opacity: 0;
            transform: translateY(-20px);
            animation: fadeInUp 0.8s forwards 0.2s;
        }

        .header-content p {
            font-size: 1.2rem;
            max-width: 700px;
            margin: 0 auto;
            opacity: 0;
            transform: translateY(-20px);
            animation: fadeInUp 0.8s forwards 0.4s;
        }

        .version-badge {
            display: inline-block;
            background: rgba(255, 255, 255, 0.2);
            padding: 5px 15px;
            border-radius: 20px;
            margin-top: 20px;
            font-weight: 600;
            backdrop-filter: blur(10px);
            opacity: 0;
            animation: fadeInUp 0.8s forwards 0.6s;
        }

        .language-switcher {
            position: absolute;
            top: 20px;
            right: 20px;
            z-index: 10;
        }

        .language-btn {
            background: rgba(255, 255, 255, 0.2);
            border: none;
            color: white;
            padding: 8px 16px;
            margin-left: 10px;
            border-radius: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
        }

        .language-btn:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }

        .main-content {
            background: var(--card-bg);
            border-radius: 20px;
            box-shadow: 0 20px 40px var(--shadow-color);
            margin-top: -60px;
            position: relative;
            z-index: 3;
            overflow: hidden;
        }

        nav {
            background: var(--bg-secondary);
            padding: 20px 0;
            border-bottom: 1px solid var(--border-color);
            position: sticky;
            top: 0;
            z-index: 5;
            backdrop-filter: blur(10px);
            background: rgba(233, 236, 239, 0.95);
        }

        .nav-links {
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
        }

        .nav-link {
            color: var(--text-secondary);
            text-decoration: none;
            padding: 8px 16px;
            border-radius: 20px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .nav-link:hover {
            background: var(--primary-color);
            color: white;
            transform: translateY(-2px);
        }

        .content-wrapper {
            padding: 40px;
        }

        section {
            margin-bottom: 60px;
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 0.8s forwards;
        }

        section:nth-child(1) { animation-delay: 0.2s; }
        section:nth-child(2) { animation-delay: 0.4s; }
        section:nth-child(3) { animation-delay: 0.6s; }
        section:nth-child(4) { animation-delay: 0.8s; }
        section:nth-child(5) { animation-delay: 1.0s; }
        section:nth-child(6) { animation-delay: 1.2s; }

        h2 {
            font-size: 2.2rem;
            margin-bottom: 30px;
            color: var(--primary-color);
            position: relative;
            padding-bottom: 15px;
        }

        h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 60px;
            height: 4px;
            background: var(--highlight-gradient);
            border-radius: 2px;
        }

        h3 {
            font-size: 1.5rem;
            margin: 30px 0 20px;
            color: var(--secondary-color);
        }

        p {
            margin-bottom: 20px;
            font-size: 1.05rem;
            color: var(--text-secondary);
        }

        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .feature-box {
            background: var(--bg-secondary);
            border-radius: 15px;
            padding: 30px;
            transition: all 0.3s ease;
            border: 1px solid var(--border-color);
            position: relative;
            overflow: hidden;
        }

        .feature-box::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 4px;
            background: var(--highlight-gradient);
            transform: scaleX(0);
            transform-origin: left;
            transition: transform 0.3s ease;
        }

        .feature-box:hover {
            transform: translateY(-10px);
            box-shadow: 0 15px 30px var(--shadow-color);
        }

        .feature-box:hover::before {
            transform: scaleX(1);
        }

        .feature-box h3 {
            margin-top: 0;
            font-size: 1.3rem;
            margin-bottom: 15px;
        }

        .feature-box ul {
            padding-left: 20px;
            margin-bottom: 20px;
        }

        .feature-box li {
            margin-bottom: 8px;
            color: var(--text-secondary);
        }

        .block-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .block-item {
            background: var(--card-bg);
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 5px 15px var(--shadow-color);
            border: 1px solid var(--border-color);
            transition: all 0.3s ease;
        }

        .block-item:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px var(--shadow-color);
        }

        .block-name {
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--primary-color);
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid var(--accent-color);
        }

        .block-usage {
            background: var(--bg-secondary);
            padding: 10px 15px;
            border-radius: 8px;
            margin: 15px 0;
            font-family: monospace;
            font-size: 0.9rem;
            color: var(--text-primary);
            border-left: 4px solid var(--primary-color);
        }

        .block-parameters {
            padding-left: 20px;
            margin: 15px 0;
        }

        .block-parameters li {
            margin-bottom: 8px;
            color: var(--text-secondary);
        }

        .application-example {
            margin-bottom: 30px;
        }

        .application-example .feature-box {
            background: linear-gradient(135deg, #f8f9fa, #e9ecef);
            border: none;
        }

        .tech-details {
            background: var(--bg-secondary);
            padding: 30px;
            border-radius: 15px;
            margin-top: 40px;
        }

        .tech-details ul {
            padding-left: 20px;
            margin-top: 20px;
        }

        .tech-details li {
            margin-bottom: 10px;
            color: var(--text-secondary);
        }

        .visualization-showcase {
            background: linear-gradient(135deg, #f0f9ff, #e0f2fe);
            border-radius: 15px;
            padding: 30px;
            margin: 40px 0;
            border: 1px solid var(--border-color);
        }

        .visualization-features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .visualization-feature {
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 5px 15px var(--shadow-color);
            transition: all 0.3s ease;
            text-align: center;
        }

        .visualization-feature:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px var(--shadow-color);
        }

        .visualization-feature h4 {
            color: var(--primary-color);
            margin-bottom: 15px;
            font-size: 1.2rem;
        }

        .animation-demo {
            background: var(--text-primary);
            border-radius: 10px;
            height: 120px;
            margin: 20px 0;
            position: relative;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .neuron-pulse {
            width: 20px;
            height: 20px;
            background: var(--accent-color);
            border-radius: 50%;
            animation: pulse 2s infinite;
            position: absolute;
        }

        .particle {
            position: absolute;
            width: 4px;
            height: 4px;
            background: var(--accent-color);
            border-radius: 50%;
            opacity: 0;
        }

        footer {
            background: var(--text-primary);
            color: white;
            padding: 40px 0;
            text-align: center;
            margin-top: 60px;
        }

        footer p {
            color: rgba(255, 255, 255, 0.7);
            margin-bottom: 10px;
        }

        /* Animations */
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes backgroundPulse {
            from {
                transform: scale(1);
                opacity: 0.5;
            }
            to {
                transform: scale(1.1);
                opacity: 0.8;
            }
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
                opacity: 1;
                box-shadow: 0 0 0 0 rgba(76, 201, 240, 0.7);
            }
            70% {
                transform: scale(1.5);
                opacity: 0.5;
                box-shadow: 0 0 0 20px rgba(76, 201, 240, 0);
            }
            100% {
                transform: scale(1);
                opacity: 0;
                box-shadow: 0 0 0 0 rgba(76, 201, 240, 0);
            }
        }
        
        /* Neuron Pulse Animation */
        .neuron-pulse {
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        
        .neuron-pulse-effect {
            position: absolute;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background-color: var(--accent-color);
            transform: scale(1);
            opacity: 0.5;
            pointer-events: none;
            z-index: 1;
            transition: transform 2s cubic-bezier(0.175, 0.885, 0.32, 1.275), 
                        opacity 2s ease-out;
        }
        
        /* Background Animated Elements */
        .bg-animated-element {
            position: fixed;
            background-color: var(--primary-color);
            border-radius: 50%;
            pointer-events: none;
            z-index: -1;
            transform: translateY(0);
            transition: transform 10s ease-out, opacity 10s ease-out;
        }
        
        /* Navigation Link Effects */
        .nav-link {
            transition: all 0.3s ease;
            position: relative;
        }
        
        .nav-link.active {
            color: var(--accent-color);
            font-weight: 600;
        }
        
        .nav-link.active::after {
            content: '';
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 100%;
            height: 2px;
            background-color: var(--accent-color);
            border-radius: 2px;
        }
        
        /* Enhanced Particle Styles */
        .particle {
            box-shadow: 0 0 6px rgba(255, 255, 255, 0.8);
        }
        
        /* Scroll Reveal Animation Styles */
        .feature-box,
        .block-item,
        .visualization-feature {
            will-change: transform, opacity;
            transition: all 0.5s ease;
        }
        
        /* Interactive Element Enhancements */
        .feature-box:hover,
        .block-item:hover,
        .visualization-feature:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.1);
        }
        
        /* Button Animation */
        button {
            transition: all 0.3s ease;
            will-change: transform;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 15px rgba(0, 0, 0, 0.1);
        }
        
        button:active {
            transform: translateY(1px);
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
        }

        /* Responsive Design */
        /* Mobile Devices (Small Screens) */
        @media (max-width: 480px) {
            .header-content h1 {
                font-size: 1.8rem;
            }

            .header-content p {
                font-size: 0.9rem;
            }

            .version-badge {
                font-size: 0.8rem;
                padding: 4px 8px;
            }

            .content-wrapper {
                padding: 15px;
            }

            h2 {
                font-size: 1.6rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .feature-grid,
            .block-grid,
            .visualization-features {
                grid-template-columns: 1fr;
                gap: 15px;
            }

            .nav-links {
                flex-wrap: wrap;
                gap: 8px;
                justify-content: center;
            }

            .nav-link {
                padding: 4px 8px;
                font-size: 0.8rem;
                white-space: nowrap;
            }

            .animation-demo {
                height: 200px;
            }

            .demo-shape {
                width: 80px;
                height: 80px;
            }

            .language-switcher {
                position: static;
                margin-bottom: 15px;
                justify-content: center;
            }
        }

        /* Tablets and Medium Screens */
        @media (min-width: 481px) and (max-width: 768px) {
            .header-content h1 {
                font-size: 2rem;
            }

            .header-content p {
                font-size: 1rem;
            }

            .content-wrapper {
                padding: 20px;
            }

            h2 {
                font-size: 1.8rem;
            }

            h3 {
                font-size: 1.3rem;
            }

            .feature-grid,
            .block-grid,
            .visualization-features {
                grid-template-columns: 1fr;
            }

            .nav-links {
                gap: 10px;
            }

            .nav-link {
                padding: 6px 12px;
                font-size: 0.9rem;
            }

            .animation-demo {
                height: 250px;
            }
        }

        /* Small Desktops */
        @media (min-width: 769px) and (max-width: 1024px) {
            .feature-grid,
            .block-grid {
                grid-template-columns: repeat(2, 1fr);
            }

            .visualization-features {
                grid-template-columns: 1fr;
            }
        }

        /* Large Desktops */
        @media (min-width: 1025px) and (max-width: 1200px) {
            .feature-grid {
                grid-template-columns: repeat(3, 1fr);
            }

            .block-grid {
                grid-template-columns: repeat(2, 1fr);
            }

            .visualization-features {
                grid-template-columns: repeat(2, 1fr);
            }
        }

        /* Extra Large Screens */
        @media (min-width: 1201px) {
            .feature-grid,
            .block-grid,
            .visualization-features {
                grid-template-columns: repeat(3, 1fr);
            }

            .container {
                max-width: 1400px;
                margin: 0 auto;
            }
        }

        /* Touch Device Optimizations */
        @media (hover: none) and (pointer: coarse) {
            .feature-box:hover,
            .block-item:hover,
            .visualization-feature:hover {
                transform: translateY(0);
                box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
            }

            .nav-link:hover {
                transform: translateY(0);
            }

            button:hover {
                transform: translateY(0);
            }
        }

        /* Animation Performance Optimizations for Mobile */
        @media (max-width: 768px) {
            .bg-animated-element {
                display: none;
            }

            .nav-link.active::after {
                height: 3px;
            }

            .neuron-pulse-effect {
                width: 30px;
                height: 30px;
            }
        }
    </style>
</head>
<body>
    <div class="language-switcher">
        <button id="zh-btn" class="language-btn">中文</button>
        <button id="en-btn" class="language-btn">English</button>
    </div>

    <header>
        <div class="container header-content">
            <h1>神经网络扩展</h1>
            <p>简单、直观的神经网络实现，让人工智能触手可及</p>
            <div class="version-badge">版本 1.73</div>
        </div>
    </header>

    <div class="container">
        <div class="main-content">
            <nav>
                <div class="nav-links">
                    <a href="#intro" class="nav-link">概述</a>
                    <a href="#features" class="nav-link">主要特点</a>
                    <a href="#usage" class="nav-link">使用流程</a>
                    <a href="#blocks" class="nav-link">积木功能</a>
                    <a href="#applications" class="nav-link">应用场景</a>
                    <a href="#visualization" class="nav-link">可视化</a>
                    <a href="#tech" class="nav-link">技术细节</a>
                </div>
            </nav>

            <div class="content-wrapper">
                <!-- 中文内容 -->
                <div class="chinese-content">
                    <section id="intro">
                        <h2>神经网络扩展概述</h2>
                        <p>神经网络扩展是一个功能强大且易于使用的编程工具，它允许用户以可视化和交互式的方式创建、训练和部署神经网络模型。无论您是神经网络初学者还是有经验的开发者，这个扩展都能帮助您快速实现各种人工智能应用。</p>
                        <p>版本 1.73 带来了全新的神经元可视化功能和界面优化，让用户能够直观地观察神经网络的工作原理和训练过程，大大提升了学习和开发体验。</p>
                    </section>

                    <section id="features">
                        <h2>主要特点</h2>
                        <div class="feature-grid">
                            <div class="feature-box">
                                <h3>直观的可视化界面</h3>
                                <p>1.73 版本全新的神经元可视化系统，实时展示网络结构、神经元状态和信号流动，让复杂的神经网络变得一目了然。</p>
                            </div>
                            <div class="feature-box">
                                <h3>灵活的网络构建</h3>
                                <p>支持自定义神经网络结构，可自由添加、删除神经元和调整网络参数，满足各种不同的应用需求。</p>
                            </div>
                            <div class="feature-box">
                                <h3>高效的训练算法</h3>
                                <p>采用反向传播算法进行网络训练，支持多种训练模式和参数调整，实现快速收敛和优化。</p>
                            </div>
                            <div class="feature-box">
                                <h3>丰富的交互功能</h3>
                                <p>支持拖拽操作、实时参数调整和动态网络修改，让用户能够直观地控制和调整神经网络的行为。</p>
                            </div>
                            <div class="feature-box">
                                <h3>多种应用场景</h3>
                                <p>适用于模式识别、预测系统、逻辑运算等多种应用场景，帮助用户实现各种智能功能。</p>
                            </div>
                            <div class="feature-box">
                                <h3>优化的动画效果</h3>
                                <p>新增神经元脉动效果和信号流粒子动画，生动展示神经网络内部的工作状态和信息传递过程。</p>
                            </div>
                        </div>
                    </section>

                    <section id="usage">
                        <h2>基本使用流程</h2>
                        <ol>
                            <li><strong>创建神经网络</strong>：使用积木块定义输入层、隐藏层和输出层的神经元数量，建立网络结构。</li>
                            <li><strong>配置网络参数</strong>：设置学习率、神经元偏置和权重等参数，优化网络性能。</li>
                            <li><strong>训练网络</strong>：提供输入数据和目标输出，通过多次训练让网络学习数据中的模式和规律。</li>
                            <li><strong>可视化监控</strong>：使用可视化面板实时观察训练进度、误差变化和网络状态。</li>
                            <li><strong>应用网络</strong>：训练完成后，使用训练好的网络进行预测和推理，应用于实际场景。</li>
                        </ol>

                        <h3>可视化面板说明</h3>
                        <p>1.73 版本的可视化面板提供了丰富的功能，帮助用户直观地了解神经网络的工作状态：</p>
                        <ul>
                            <li>实时展示网络结构和连接方式</li>
                            <li>显示神经元激活状态和输出值</li>
                            <li>可视化信号在网络中的流动过程</li>
                            <li>展示训练过程中的误差变化曲线</li>
                            <li>支持交互式调整和实时参数修改</li>
                        </ul>
                    </section>

                    <section id="visualization">
                        <h2>神经元可视化功能</h2>
                        <div class="visualization-showcase">
                            <p>1.73 版本引入了全新的神经元可视化系统，让神经网络的工作原理变得直观可见。这一功能通过多种动画效果展示神经网络内部的活动状态，帮助用户更好地理解和调试网络行为。</p>
                            
                            <div class="animation-demo">
                                <div class="neuron-pulse"></div>
                            </div>
                            
                            <div class="visualization-features">
                                <div class="visualization-feature">
                                    <h4>神经元脉动效果</h4>
                                    <p>当神经元被激活时，会产生脉动动画，直观展示神经元的活跃状态和信号强度。</p>
                                </div>
                                <div class="visualization-feature">
                                    <h4>粒子信号流</h4>
                                    <p>通过流动的粒子动画展示信息如何在神经元之间传递，让信号传导过程可视化。</p>
                                </div>
                                <div class="visualization-feature">
                                    <h4>交互式调整</h4>
                                    <p>支持直接在可视化界面上调整网络参数，实时观察调整效果。</p>
                                </div>
                                <div class="visualization-feature">
                                    <h4>训练过程监控</h4>
                                    <p>实时显示训练进度和误差变化，帮助优化训练策略。</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <section id="blocks">
                        <h2>积木块功能详解</h2>
                        
                        <h3>网络构建类积木</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">创建神经网络 [输入层神经元数] [隐藏层神经元数] [输出层神经元数]</div>
                                <p><strong>功能</strong>：创建一个新的神经网络，定义输入层、隐藏层和输出层的神经元数量。这是使用神经网络扩展的第一步，必须先创建网络才能进行后续操作。</p>
                                <div class="block-usage">创建神经网络 2 3 1</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>输入层神经元数 - 网络输入节点的数量，决定了可以处理的数据维度</li>
                                    <li>隐藏层神经元数 - 网络中间层节点的数量，影响网络的学习能力</li>
                                    <li>输出层神经元数 - 网络输出节点的数量，决定了输出结果的维度</li>
                                </ul>
                                <p><strong>作用</strong>：建立神经网络的基本框架，为后续的参数设置和训练奠定基础。网络结构直接影响其学习能力和适用场景，需要根据具体问题进行合理设计。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">添加神经元到层 [层数]</div>
                                <p><strong>功能</strong>：在指定层中添加一个新的神经元，动态调整网络结构。这一功能使得网络结构可以根据需求灵活变化。</p>
                                <div class="block-usage">添加神经元到层 2</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>层数 - 目标层的索引，从1开始计数（1为输入层，最后一层为输出层）</li>
                                </ul>
                                <p><strong>作用</strong>：通过动态调整网络结构，增强或调整网络的学习能力。当发现现有网络结构无法很好地拟合数据时，可以通过添加神经元来增强网络的表达能力。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">从层 [层数] 删除神经元</div>
                                <p><strong>功能</strong>：从指定层中随机删除一个神经元，减少网络复杂度。这有助于防止过拟合和简化模型。</p>
                                <div class="block-usage">从层 2 删除神经元</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>层数 - 目标层的索引，从1开始计数</li>
                                </ul>
                                <p><strong>作用</strong>：当网络过于复杂导致过拟合，或者想要简化模型以提高泛化能力时，可以通过删除神经元来减少网络复杂度。每个层至少需要保留一个神经元。</p>
                            </div>
                        </div>

                        <h3>参数设置类积木</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">设置层 [层数] 神经元 [神经元索引] 的偏置为 [值]</div>
                                <p><strong>功能</strong>：设置指定层中特定神经元的偏置值。偏置值是神经网络中的重要参数，影响神经元的激活阈值。</p>
                                <div class="block-usage">设置层 2 神经元 1 的偏置为 0.5</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>层数 - 目标层的索引，从1开始计数</li>
                                    <li>神经元索引 - 层内神经元的索引，从1开始计数</li>
                                    <li>值 - 偏置的目标值，通常为-1到1之间的实数</li>
                                </ul>
                                <p><strong>作用</strong>：偏置值相当于神经元的激活阈值，可以调整神经元对输入信号的敏感程度。通过手动设置偏置，可以对神经网络的行为进行更精细的控制。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">设置层 [层数] 神经元 [神经元索引] 权重 [权重索引] 为 [值]</div>
                                <p><strong>功能</strong>：设置指定层中特定神经元与前一层神经元之间的连接权重。权重决定了信号传递的强度和方向。</p>
                                <div class="block-usage">设置层 2 神经元 1 权重 2 为 0.8</div>
                                <p><strong>参数说明</strong>：</p>
                                    <ul class="block-parameters">
                                    <li>层数 - 目标层的索引，从2开始计数（因为输入层没有前层权重）</li>
                                    <li>神经元索引 - 当前层内神经元的索引，从1开始计数</li>
                                    <li>权重索引 - 连接的前一层神经元索引，从1开始计数</li>
                                    <li>值 - 权重的目标值，通常为-1到1之间的实数</li>
                                </ul>
                                <p><strong>作用</strong>：权重是神经网络学习的核心参数，决定了不同输入信号对神经元输出的贡献程度。通过手动设置权重，可以对网络进行精细调整或直接实现特定功能。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">设置学习率为 [值]</div>
                                <p><strong>功能</strong>：设置神经网络的学习率参数，控制训练过程中权重和偏置的更新步长。</p>
                                <div class="block-usage">设置学习率为 0.1</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>值 - 学习率的大小，通常为0.01到1之间的正数</li>
                                </ul>
                                <p><strong>作用</strong>：学习率直接影响训练效果和速度。较大的学习率使网络参数更新更快，训练速度较快但可能无法收敛到最优解；较小的学习率使参数更新更精确，可能找到更好的解，但训练速度较慢且可能陷入局部最优。合适的学习率需要根据具体问题进行调整。</p>
                            </div>
                        </div>

                        <h3>训练与预测类积木</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">使用输入 [数据] 和目标 [数据] 训练一次</div>
                                <p><strong>功能</strong>：使用一组输入数据和对应的目标输出数据进行一次训练迭代。网络根据预测结果与目标值的差异，通过反向传播算法更新内部参数。</p>
                                <div class="block-usage">使用输入 [0,1] 和目标 [1] 训练一次</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>输入数据 - 与输入层神经元数量匹配的数组（例如，如果输入层有2个神经元，输入应为包含2个元素的数组）</li>
                                    <li>目标数据 - 与输出层神经元数量匹配的数组（例如，如果输出层有1个神经元，目标应为包含1个元素的数组）</li>
                                </ul>
                                <p><strong>作用</strong>：这是网络学习的基本单位操作。每次训练，网络根据误差调整权重和偏置，使得下次对相同输入的预测更接近目标值。单次训练的效果有限，通常需要多次训练才能取得良好效果。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">重复训练 [次数]</div>
                                <p><strong>功能</strong>：重复执行最近设置的训练数据（输入和目标）指定次数，自动进行多次训练迭代。</p>
                                <div class="block-usage">重复训练 1000 次</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>次数 - 训练的重复次数（通常为数百到数千次，复杂问题可能需要数万次）</li>
                                </ul>
                                <p><strong>作用</strong>：通过多次重复训练，网络可以逐渐学习数据中的模式和规律，不断减少预测误差。训练次数太少可能导致学习不充分；太多则可能导致过拟合和训练时间过长。合适的训练次数可以通过观察误差曲线来确定。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">输入 [数据] 获取输出</div>
                                <p><strong>功能</strong>：使用训练好的网络进行预测，将输入数据通过网络前向传播计算得到输出结果。这是应用训练好的网络进行实际预测的核心操作。</p>
                                <div class="block-usage">输入 [0,1] 获取输出</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>输入数据 - 与输入层神经元数量匹配的数组（与训练时的输入数据格式相同）</li>
                                </ul>
                                <p><strong>作用</strong>：这是神经网络的应用阶段。网络完全训练好后，输入新的数据，网络将基于学习到的模式进行预测并输出相应结果。例如，在图像识别中，输入图像数据，网络输出识别结果；在预测系统中，输入特征数据，网络输出预测值。</p>
                            </div>
                        </div>

                        <h3>可视化与信息类积木</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">显示/隐藏可视化面板</div>
                                <p><strong>功能</strong>：控制训练可视化面板的显示和隐藏状态，方便在需要时查看训练过程，不需要时关闭以节省屏幕空间。</p>
                                <div class="block-usage">显示可视化面板</div>
                                <p><strong>作用</strong>：可视化面板是监控训练过程的重要工具。训练开始时显示面板，可以实时观察误差变化和网络状态，判断训练是否正常进行；训练完成后，可以隐藏面板，专注于网络应用和结果分析。1.73版本的可视化面板新增了神经元脉动效果和信号流粒子动画，让网络状态更直观。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">获取层 [层数] 神经元 [神经元索引] 的输出</div>
                                <p><strong>功能</strong>：查询指定神经元在当前状态下的输出值，了解网络内部各神经元的激活情况。</p>
                                <div class="block-usage">获取层 2 神经元 3 的输出</div>
                                <p><strong>参数说明</strong>：</p>
                                <ul class="block-parameters">
                                    <li>层数 - 层编号（从1开始计数）</li>
                                    <li>神经元索引 - 层内神经元编号（从1开始计数）</li>
                                </ul>
                                <p><strong>作用</strong>：这是网络调试和分析的重要工具。通过查看各层神经元的输出，可以了解网络如何处理输入数据，哪些神经元被激活以及激活强度如何。这有助于理解网络的工作原理，发现网络结构中的问题，并进一步优化网络设计。</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">获取当前误差值</div>
                                <p><strong>功能</strong>：获取网络最近一次训练后的误差值，定量评估网络的训练效果。误差值越小，表示网络的预测结果越接近目标值。</p>
                                <div class="block-usage">获取当前误差值</div>
                                <p><strong>作用</strong>：误差值是判断网络训练效果的关键指标。通过监控误差值的变化，可以了解训练是否有效进行，是否需要继续训练，或是否需要调整学习率等参数。当误差值不再明显下降时，通常表明网络已经取得了良好的训练效果。</p>
                            </div>
                        </div>
                    </section>

                    <section id="applications">
                        <h2>示例应用场景</h2>
                        
                        <div class="application-example">
                            <div class="feature-box">
                                <h3>模式识别</h3>
                                <p>训练网络识别简单的模式和规律，例如：</p>
                                <ul>
                                    <li>识别不同的几何形状（圆形、正方形、三角形）</li>
                                    <li>识别颜色组合或简单图像特征</li>
                                    <li>识别特定的声音模式或序列</li>
                                </ul>
                                <p><strong>实现思路</strong>：将模式的特征数据作为输入，对应的模式类别作为目标输出，训练网络学习特征与类别的对应关系。训练完成后，网络可以对新的模式进行分类识别。</p>
                            </div>
                        </div>

                        <div class="application-example">
                            <div class="feature-box">
                                <h3>预测系统</h3>
                                <p>根据输入数据预测可能的输出结果，例如：</p>
                                <ul>
                                    <li>根据温度、湿度等数据预测天气状况</li>
                                    <li>根据历史销售数据预测未来销售额</li>
                                    <li>根据学生学习时间预测考试成绩</li>
                                </ul>
                                <p><strong>实现思路</strong>：使用历史数据进行训练，将影响因素作为输入，将待预测的结果作为目标输出。网络将学习输入和输出之间的潜在关系；训练完成后，输入新的影响因素数据，即可得到预测结果。</p>
                            </div>
                        </div>

                        <div class="application-example">
                            <div class="feature-box">
                                <h3>逻辑运算</h3>
                                <p>训练网络实现基本的逻辑运算，理解神经网络的学习机制：</p>
                                <ul>
                                    <li>实现异或（XOR）运算，一个经典的非线性问题</li>
                                    <li>实现与（AND）、或（OR）等基本逻辑运算</li>
                                    <li>组合实现更复杂的逻辑判断</li>
                                </ul>
                                <p><strong>实现思路</strong>：将逻辑运算的输入（0或1）作为网络输入，运算结果作为目标输出。通过训练，网络可以在不知道"逻辑"概念的情况下学习这些逻辑关系。这是理解神经网络如何学习复杂关系的一个很好的例子。</p>
                            </div>
                        </div>
                    </section>

                    <section id="tech" class="tech-details">
                        <h2>技术细节</h2>
                        <p>本神经网络扩展采用以下技术和算法，确保功能实现和性能优化：</p>
                        <ul>
                            <li><strong>激活函数</strong>：使用Sigmoid函数作为神经元的激活函数，将神经元的输入映射到0到1之间的输出，使网络能够学习非线性关系</li>
                            <li><strong>训练算法</strong>：采用反向传播算法进行网络训练，通过计算预测误差并将其反向传播到各层，指导权重和偏置的更新</li>
                            <li><strong>误差计算</strong>：使用均方误差（MSE）作为误差度量，计算预测值与目标值之间的平均平方差</li>
                            <li><strong>学习方法</strong>：结合批量学习和在线学习，支持单次训练和多次重复训练</li>
                            <li><strong>可视化技术</strong>：使用Canvas绘图API实现神经网络结构可视化，通过requestAnimationFrame实现流畅的动画效果</li>
                            <li><strong>动画系统</strong>：实现了神经元脉动效果和粒子信号流模拟，生动展示神经网络内部活动</li>
                        </ul>
                    </section>
                </div>

                <!-- English content -->
                <div class="english-content" style="display: none;">
                    <section id="intro">
                        <h2>Neural Network Extension Overview</h2>
                        <p>The Neural Network Extension is a powerful and user-friendly programming tool that allows users to create, train, and deploy neural network models in a visual and interactive way. Whether you are a beginner in neural networks or an experienced developer, this extension helps you quickly implement various artificial intelligence applications.</p>
                        <p>Version 1.73 introduces new neuron visualization features and interface optimizations, allowing users to intuitively observe the working principles and training process of neural networks, greatly enhancing the learning and development experience.</p>
                    </section>

                    <section id="features">
                        <h2>Key Features</h2>
                        <div class="feature-grid">
                            <div class="feature-box">
                                <h3>Intuitive Visualization Interface</h3>
                                <p>Version 1.73's new neuron visualization system displays network structure, neuron states, and signal flow in real-time, making complex neural networks easy to understand.</p>
                            </div>
                            <div class="feature-box">
                                <h3>Flexible Network Construction</h3>
                                <p>Support for customizing neural network structures, freely adding and removing neurons, and adjusting network parameters to meet various application requirements.</p>
                            </div>
                            <div class="feature-box">
                                <h3>Efficient Training Algorithms</h3>
                                <p>Uses backpropagation algorithm for network training, supports multiple training modes and parameter adjustments for fast convergence and optimization.</p>
                            </div>
                            <div class="feature-box">
                                <h3>Rich Interactive Features</h3>
                                <p>Supports drag-and-drop operations, real-time parameter adjustments, and dynamic network modifications, allowing users to intuitively control and adjust neural network behavior.</p>
                            </div>
                            <div class="feature-box">
                                <h3>Multiple Application Scenarios</h3>
                                <p>Suitable for pattern recognition, prediction systems, logical operations, and many other application scenarios, helping users implement various intelligent functions.</p>
                            </div>
                            <div class="feature-box">
                                <h3>Optimized Animation Effects</h3>
                                <p>New neuron pulsing effects and particle signal flow animations vividly demonstrate the internal working state and information transfer process of neural networks.</p>
                            </div>
                        </div>
                    </section>

                    <section id="usage">
                        <h2>Basic Usage Process</h2>
                        <ol>
                            <li><strong>Create Neural Network</strong>: Use blocks to define the number of neurons in the input layer, hidden layer, and output layer to establish the network structure.</li>
                            <li><strong>Configure Network Parameters</strong>: Set learning rate, neuron bias, weights, and other parameters to optimize network performance.</li>
                            <li><strong>Train Network</strong>: Provide input data and target output, and train the network multiple times to learn patterns and rules in the data.</li>
                            <li><strong>Visualization Monitoring</strong>: Use the visualization panel to observe training progress, error changes, and network status in real-time.</li>
                            <li><strong>Apply Network</strong>: After training, use the trained network for prediction and inference, and apply it to practical scenarios.</li>
                        </ol>

                        <h3>Visualization Panel Description</h3>
                        <p>The visualization panel in version 1.73 provides rich features to help users intuitively understand the working status of neural networks:</p>
                        <ul>
                            <li>Real-time display of network structure and connection methods</li>
                            <li>Show neuron activation status and output values</li>
                            <li>Visualize signal flow process in the network</li>
                            <li>Display error change curves during training</li>
                            <li>Support interactive adjustment and real-time parameter modification</li>
                        </ul>
                    </section>

                    <section id="visualization">
                        <h2>Neuron Visualization Features</h2>
                        <div class="visualization-showcase">
                            <p>Version 1.73 introduces a new neuron visualization system, making the working principles of neural networks intuitively visible. This feature demonstrates the internal activity state of neural networks through various animation effects, helping users better understand and debug network behavior.</p>
                            
                            <div class="animation-demo">
                                <div class="neuron-pulse"></div>
                            </div>
                            
                            <div class="visualization-features">
                                <div class="visualization-feature">
                                    <h4>Neuron Pulsing Effects</h4>
                                    <p>When neurons are activated, they produce pulsing animations, intuitively showing neuron activity status and signal intensity.</p>
                                </div>
                                <div class="visualization-feature">
                                    <h4>Particle Signal Flow</h4>
                                    <p>Shows how information is transmitted between neurons through flowing particle animations, making the signal conduction process visible.</p>
                                </div>
                                <div class="visualization-feature">
                                    <h4>Interactive Adjustment</h4>
                                    <p>Supports direct adjustment of network parameters on the visualization interface, and observes adjustment effects in real-time.</p>
                                </div>
                                <div class="visualization-feature">
                                    <h4>Training Process Monitoring</h4>
                                    <p>Real-time display of training progress and error changes, helping to optimize training strategies.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <section id="blocks">
                        <h2>Block Functionality Details</h2>
                        
                        <h3>Network Construction Blocks</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">Create Neural Network [input neurons] [hidden neurons] [output neurons]</div>
                                <p><strong>Function</strong>: Creates a new neural network, defining the number of neurons in the input, hidden, and output layers. This is the first step in using the neural network extension; you must create a network before proceeding with subsequent operations.</p>
                                <div class="block-usage">Create Neural Network 2 3 1</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Input neurons - The number of network input nodes, determining the dimension of data that can be processed</li>
                                    <li>Hidden neurons - The number of network middle layer nodes, affecting the network's learning ability</li>
                                    <li>Output neurons - The number of network output nodes, determining the dimension of output results</li>
                                </ul>
                                <p><strong>Effect</strong>: Establishes the basic framework of the neural network, laying the foundation for subsequent parameter settings and training. The network structure directly affects its learning ability and applicable scenarios and needs to be reasonably designed according to specific problems.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Add Neuron to Layer [layer number]</div>
                                <p><strong>Function</strong>: Adds a new neuron to the specified layer, dynamically adjusting the network structure. This feature allows the network structure to flexibly change according to requirements.</p>
                                <div class="block-usage">Add Neuron to Layer 2</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Layer number - The index of the target layer, counted from 1 (1 for input layer, last layer for output layer)</li>
                                </ul>
                                <p><strong>Effect</strong>: By dynamically adjusting the network structure, enhance or adjust the learning ability of the network. When it is found that the existing network structure cannot fit the data well, neurons can be added to enhance the network's expressive ability.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Remove Neuron from Layer [layer number]</div>
                                <p><strong>Function</strong>: Randomly removes a neuron from the specified layer, reducing network complexity. This helps prevent overfitting and simplifies the model.</p>
                                <div class="block-usage">Remove Neuron from Layer 2</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Layer number - The index of the target layer, counted from 1</li>
                                </ul>
                                <p><strong>Effect</strong>: When the network is too complex leading to overfitting, or you want to simplify the model to improve generalization ability, you can reduce network complexity by removing neurons. Each layer must retain at least one neuron.</p>
                            </div>
                        </div>

                        <h3>Parameter Setting Blocks</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">Set Bias of Neuron [neuron index] in Layer [layer number] to [value]</div>
                                <p><strong>Function</strong>: Sets the bias value of a specific neuron in the specified layer. Bias is an important parameter in neural networks that affects the activation threshold of neurons.</p>
                                <div class="block-usage">Set Bias of Neuron 1 in Layer 2 to 0.5</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Layer number - The index of the target layer, counted from 1</li>
                                    <li>Neuron index - The index of the neuron within the layer, counted from 1</li>
                                    <li>Value - The target value of the bias, usually a real number between -1 and 1</li>
                                </ul>
                                <p><strong>Effect</strong>: The bias value is equivalent to the activation threshold of the neuron, which can adjust the sensitivity of the neuron to input signals. By manually setting biases, you can perform more precise control over the behavior of neural networks.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Set Weight [weight index] of Neuron [neuron index] in Layer [layer number] to [value]</div>
                                <p><strong>Function</strong>: Sets the connection weight between a specific neuron in the specified layer and a neuron in the previous layer. Weights determine the strength and direction of signal transmission.</p>
                                <div class="block-usage">Set Weight 2 of Neuron 1 in Layer 2 to 0.8</div>
                                <p><strong>Parameter Description</strong>:</p>
                                    <ul class="block-parameters">
                                    <li>Layer number - The index of the target layer, counted from 2 (since the input layer has no previous layer weights)</li>
                                    <li>Neuron index - The index of the neuron within the current layer, counted from 1</li>
                                    <li>Weight index - The index of the connected neuron in the previous layer, counted from 1</li>
                                    <li>Value - The target value of the weight, usually a real number between -1 and 1</li>
                                </ul>
                                <p><strong>Effect</strong>: Weights are the core parameters learned by neural networks, determining the contribution of different input signals to neuron output. By manually setting weights, you can fine-tune the network or directly implement specific functions.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Set Learning Rate to [value]</div>
                                <p><strong>Function</strong>: Sets the learning rate parameter of the neural network, controlling the update step size of weights and biases during training.</p>
                                <div class="block-usage">Set Learning Rate to 0.1</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Value - The size of the learning rate, usually a positive number between 0.01 and 1</li>
                                </ul>
                                <p><strong>Effect</strong>: Learning rate directly affects training effectiveness and speed. A larger learning rate makes network parameter updates faster, with faster training speed but may not converge to the optimal solution; a smaller learning rate makes parameter updates more precise, may find better solutions, but with slower training speed and may fall into local optima. The appropriate learning rate needs to be adjusted according to specific problems.</p>
                            </div>
                        </div>

                        <h3>Training and Prediction Blocks</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">Train Once with Input [data] and Target [data]</div>
                                <p><strong>Function</strong>: Performs one training iteration using a set of input data and corresponding target output data. The network updates internal parameters through backpropagation algorithm based on the difference between prediction results and target values.</p>
                                <div class="block-usage">Train Once with Input [0,1] and Target [1]</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Input data - An array matching the number of input layer neurons (for example, if the input layer has 2 neurons, the input should be an array containing 2 elements)</li>
                                    <li>Target data - An array matching the number of output layer neurons (for example, if the output layer has 1 neuron, the target should be an array containing 1 element)</li>
                                </ul>
                                <p><strong>Effect</strong>: This is the basic unit operation of network learning. Each training, the network adjusts weights and biases based on errors, making predictions for the same input closer to the target value in the next time. The effect of single training is limited, and multiple trainings are usually required to achieve good results.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Repeat Training [times]</div>
                                <p><strong>Function</strong>: Repeats the most recently set training data (input and target) the specified number of times, automatically performing multiple training iterations.</p>
                                <div class="block-usage">Repeat Training 1000 times</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Times - The number of training repetitions (usually hundreds to thousands of times, complex problems may require tens of thousands of times)</li>
                                </ul>
                                <p><strong>Effect</strong>: Through multiple repeated trainings, the network can gradually learn patterns and rules in the data, continuously reducing prediction errors. Too few training times may lead to insufficient learning; too many may lead to overfitting and long training time. The appropriate number of training times can be determined by observing the error curve.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Input [data] to Get Output</div>
                                <p><strong>Function</strong>: Uses the trained network for prediction, computing output results by forward propagating input data through the network. This is the core operation of applying the trained network for actual prediction.</p>
                                <div class="block-usage">Input [0,1] to Get Output</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Input data - An array matching the number of input layer neurons (same format as input data during training)</li>
                                </ul>
                                <p><strong>Effect</strong>: This is the application phase of neural networks. After the network is fully trained, input new data, and the network will make predictions based on learned patterns and output corresponding results. For example, in image recognition, input image data, and the network outputs recognition results; in prediction systems, input feature data, and the network outputs predicted values.</p>
                            </div>
                        </div>

                        <h3>Visualization and Information Blocks</h3>
                        <div class="block-grid">
                            <div class="block-item">
                                <div class="block-name">Show/Hide Visualization Panel</div>
                                <p><strong>Function</strong>: Controls the display and hiding state of the training visualization panel, convenient for viewing the training process when needed and closing to save screen space when not needed.</p>
                                <div class="block-usage">Show Visualization Panel</div>
                                <p><strong>Effect</strong>: The visualization panel is an important tool for monitoring the training process. Display the panel at the beginning of training to observe error changes and network status in real-time, and judge whether the training is proceeding normally; after training is completed, the panel can be hidden to focus on network application and result analysis. The visualization panel in version 1.73 adds neuron pulsing effects and particle signal flow animations, making network status more intuitive.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Get Output of Neuron [neuron index] in Layer [layer number]</div>
                                <p><strong>Function</strong>: Queries the output value of the specified neuron in the current state, understanding the activation of various neurons within the network.</p>
                                <div class="block-usage">Get Output of Neuron 3 in Layer 2</div>
                                <p><strong>Parameter Description</strong>:</p>
                                <ul class="block-parameters">
                                    <li>Layer number - Layer index (counted from 1)</li>
                                    <li>Neuron index - Neuron index within the layer (counted from 1)</li>
                                </ul>
                                <p><strong>Effect</strong>: This is an important tool for network debugging and analysis. By viewing the output of neurons in each layer, you can understand how the network processes input data, which neurons are activated and how strong the activation is. This helps understand the working principle of the network, discover problems in the network structure, and further optimize network design.</p>
                            </div>

                            <div class="block-item">
                                <div class="block-name">Get Current Error Value</div>
                                <p><strong>Function</strong>: Gets the error value of the network after the most recent training, quantitatively evaluating the training effect of the network. A smaller error value indicates that the network's prediction results are closer to the target value.</p>
                                <div class="block-usage">Get Current Error Value</div>
                                <p><strong>Effect</strong>: The error value is a key indicator for judging network training effect. By monitoring changes in the error value, you can understand whether training is proceeding effectively, whether it needs to continue, or whether parameters such as learning rate need to be adjusted. When the error value no longer decreases significantly, it usually indicates that the network has achieved good training effect.</p>
                            </div>
                        </div>
                    </section>

                    <section id="applications">
                        <h2>Example Application Scenarios</h2>
                        
                        <div class="application-example">
                            <div class="feature-box">
                                <h3>Pattern Recognition</h3>
                                <p>Train the network to recognize simple patterns and rules, such as:</p>
                                <ul>
                                    <li>Recognizing different geometric shapes (circles, squares, triangles)</li>
                                    <li>Recognizing color combinations or simple image features</li>
                                    <li>Recognizing specific sound patterns or sequences</li>
                                </ul>
                                <p><strong>Implementation Idea</strong>: Use the feature data of patterns as input and the corresponding pattern categories as target output, training the network to learn the correspondence between features and categories. After training, the network can classify and recognize new patterns.</p>
                            </div>
                        </div>

                        <div class="application-example">
                            <div class="feature-box">
                                <h3>Prediction Systems</h3>
                                <p>Predict possible output results based on input data, such as:</p>
                                <ul>
                                    <li>Predicting weather conditions based on temperature, humidity, and other data</li>
                                    <li>Predicting future sales based on historical sales data</li>
                                    <li>Predicting exam scores based on students' study time</li>
                                </ul>
                                <p><strong>Implementation Idea</strong>: Use historical data for training, taking influencing factors as input and the results to be predicted as target output. The network will learn the potential relationships between input and output; after training is completed, input new influencing factor data to get predicted results.</p>
                            </div>
                        </div>

                        <div class="application-example">
                            <div class="feature-box">
                                <h3>Logical Operations</h3>
                                <p>Train the network to implement basic logical operations, understanding the learning mechanism of neural networks:</p>
                                <ul>
                                    <li>Implement XOR operation, a classic nonlinear problem</li>
                                    <li>Implement basic logical operations such as AND, OR, etc.</li>
                                    <li>Combine to implement more complex logical judgments</li>
                                </ul>
                                <p><strong>Implementation Idea</strong>: Use the inputs of logical operations (0 or 1) as network inputs and operation results as target outputs. Through training, the network can learn these logical relationships without knowing the concept of "logic". This is a good example of understanding how neural networks learn complex relationships.</p>
                            </div>
                        </div>
                    </section>

                    <section id="tech" class="tech-details">
                        <h2>Technical Details</h2>
                        <p>This neural network extension adopts the following technologies and algorithms to ensure functionality implementation and performance optimization:</p>
                        <ul>
                            <li><strong>Activation Function</strong>: Uses the Sigmoid function as the activation function of neurons, mapping the input of neurons to an output between 0 and 1, enabling the network to learn nonlinear relationships</li>
                            <li><strong>Training Algorithm</strong>: Uses backpropagation algorithm for network training, guiding the update of weights and biases by calculating prediction errors and propagating them backward to each layer</li>
                            <li><strong>Error Calculation</strong>: Uses Mean Squared Error (MSE) as the error metric, calculating the average squared difference between predicted values and target values</li>
                            <li><strong>Learning Method</strong>: Combines batch learning and online learning, supporting single training and multiple repeated training</li>
                            <li><strong>Visualization Technology</strong>: Uses Canvas drawing API to implement neural network structure visualization, and requestAnimationFrame to implement smooth animation effects</li>
                            <li><strong>Animation System</strong>: Implements neuron pulsing effects and particle signal flow simulation, vividly demonstrating internal activities of neural networks</li>
                        </ul>
                    </section>
                </div>
            </div>
        </div>
    </div>

    <footer>
        <div class="container">
            <p>Neural Network Extension &copy; 2025年11月23日geng xin</p>
            <p>Version 1.73 | Last updated: October 2023</p>
        </div>
    </footer>

    <script>
        // Language switching functionality
        document.getElementById('zh-btn').addEventListener('click', function() {
            document.querySelector('.chinese-content').style.display = 'block';
            document.querySelector('.english-content').style.display = 'none';
        });
        
        document.getElementById('en-btn').addEventListener('click', function() {
            document.querySelector('.chinese-content').style.display = 'none';
            document.querySelector('.english-content').style.display = 'block';
        });

        // Enhanced Animation System
        document.addEventListener('DOMContentLoaded', function() {
            // 1. Neuron pulse animation
            function createNeuronPulse() {
                const neuron = document.querySelector('.neuron-pulse');
                const pulse = document.createElement('div');
                pulse.className = 'neuron-pulse-effect';
                
                // Position the pulse at the center of the neuron
                const neuronRect = neuron.getBoundingClientRect();
                const demoRect = document.querySelector('.animation-demo').getBoundingClientRect();
                
                pulse.style.left = (neuronRect.width / 2) + 'px';
                pulse.style.top = (neuronRect.height / 2) + 'px';
                
                neuron.appendChild(pulse);
                
                // Animate and remove after completion
                setTimeout(() => {
                    pulse.style.transform = 'scale(3)';
                    pulse.style.opacity = '0';
                }, 10);
                
                setTimeout(() => {
                    neuron.removeChild(pulse);
                }, 2000);
            }
            
            // Create pulse effect every 2 seconds
            setInterval(createNeuronPulse, 2000);
            createNeuronPulse(); // Start immediately

            // 2. Enhanced particle animation
            const demo = document.querySelector('.animation-demo');
            const demoRect = demo.getBoundingClientRect();
            const centerX = demoRect.width / 2;
            const centerY = demoRect.height / 2;
            
            function createParticle() {
                const particle = document.createElement('div');
                particle.className = 'particle';
                particle.style.left = centerX + 'px';
                particle.style.top = centerY + 'px';
                
                // Random properties for more dynamic effect
                const size = Math.random() * 3 + 2;
                particle.style.width = size + 'px';
                particle.style.height = size + 'px';
                
                // Different colors based on probability
                const colors = [
                    'var(--primary-color)',
                    'var(--accent-color)',
                    'rgba(255, 255, 255, 0.9)'
                ];
                particle.style.background = colors[Math.floor(Math.random() * colors.length)];
                
                // Direction and distance
                const angle = Math.random() * Math.PI * 2;
                const distance = Math.random() * 100 + 50;
                const targetX = centerX + Math.cos(angle) * distance;
                const targetY = centerY + Math.sin(angle) * distance;
                
                demo.appendChild(particle);
                
                let startTime = null;
                const duration = 1500 + Math.random() * 2000;
                
                function animate(timestamp) {
                    if (!startTime) startTime = timestamp;
                    const progress = (timestamp - startTime) / duration;
                    
                    if (progress < 1) {
                        // Ease-out function for smoother start and gradual end
                        const easeProgress = 1 - Math.pow(1 - progress, 3);
                        
                        const currentX = centerX + (targetX - centerX) * easeProgress;
                        const currentY = centerY + (targetY - centerY) * easeProgress;
                        particle.style.left = currentX + 'px';
                        particle.style.top = currentY + 'px';
                        particle.style.opacity = 1 - progress;
                        
                        requestAnimationFrame(animate);
                    } else {
                        demo.removeChild(particle);
                    }
                }
                
                requestAnimationFrame(animate);
            }
            
            // More frequent particles
            setInterval(createParticle, 150);

            // 3. Scroll reveal animation
            function animateOnScroll() {
                const elements = document.querySelectorAll('.feature-box, .block-item, .visualization-feature');
                
                elements.forEach(element => {
                    const elementTop = element.getBoundingClientRect().top;
                    const windowHeight = window.innerHeight;
                    
                    if (elementTop < windowHeight * 0.9) {
                        element.style.opacity = '1';
                        element.style.transform = 'translateY(0)';
                    }
                });
            }
            
            // Initial setup for scroll animations
            document.querySelectorAll('.feature-box, .block-item, .visualization-feature').forEach(el => {
                el.style.opacity = '0';
                el.style.transform = 'translateY(20px)';
                el.style.transition = 'opacity 0.8s ease-out, transform 0.8s ease-out';
            });
            
            // Run on load and scroll
            setTimeout(animateOnScroll, 200);
            window.addEventListener('scroll', animateOnScroll);

            // 4. Interactive navigation effects
            const navLinks = document.querySelectorAll('.nav-link');
            navLinks.forEach(link => {
                link.addEventListener('mouseenter', function() {
                    this.style.transform = 'translateY(-3px)';
                });
                
                link.addEventListener('mouseleave', function() {
                    this.style.transform = 'translateY(0)';
                });
                
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    const targetId = this.getAttribute('href');
                    const targetElement = document.querySelector(targetId);
                    
                    window.scrollTo({
                        top: targetElement.offsetTop - 80,
                        behavior: 'smooth'
                    });
                    
                    // Highlight active link
                    navLinks.forEach(l => l.classList.remove('active'));
                    this.classList.add('active');
                });
            });

            // 5. Background animated elements
            function createBackgroundElement() {
                const bgElement = document.createElement('div');
                bgElement.className = 'bg-animated-element';
                
                // Random position, size and color
                const size = Math.random() * 100 + 50;
                const opacity = Math.random() * 0.05 + 0.02;
                
                bgElement.style.width = size + 'px';
                bgElement.style.height = size + 'px';
                bgElement.style.left = Math.random() * 100 + 'vw';
                bgElement.style.top = Math.random() * 300 + 'vh';
                bgElement.style.opacity = opacity;
                
                document.querySelector('body').appendChild(bgElement);
                
                // Animate up and fade out
                setTimeout(() => {
                    bgElement.style.transform = 'translateY(-200px)';
                    bgElement.style.opacity = '0';
                }, 10);
                
                setTimeout(() => {
                    document.querySelector('body').removeChild(bgElement);
                }, 10000);
            }
            
            // Create background elements periodically
            setInterval(createBackgroundElement, 3000);
            
            // Create 5 initial background elements
            for (let i = 0; i < 5; i++) {
                setTimeout(createBackgroundElement, i * 500);
            }
        });
    </script>
</body>
</html>